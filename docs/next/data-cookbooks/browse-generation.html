<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Ingest Browse Generation · Cumulus Documentation</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="# Browse Generation"/><meta name="docsearch:version" content="next"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Ingest Browse Generation · Cumulus Documentation"/><meta property="og:type" content="website"/><meta property="og:url" content="https://nasa.github.io/cumulus/"/><meta property="og:description" content="# Browse Generation"/><meta name="twitter:card" content="summary"/><link rel="shortcut icon" href="/cumulus/undefined"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/cumulus/js/scrollSpy.js"></script><link rel="stylesheet" href="/cumulus/css/main.css"/><script src="/cumulus/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/cumulus/"><h2 class="headerTitle">Cumulus Documentation</h2></a><a href="/cumulus/versions"><h3>next</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="https://nasa.github.io/cumulus-api" target="_self">API Docs</a></li><li class=""><a href="/cumulus/docs/next/cumulus-docs-readme" target="_self">Developer Docs</a></li><li class="siteNavGroupActive"><a href="/cumulus/docs/next/data-cookbooks/about-cookbooks" target="_self">Data-Cookbooks</a></li><li class=""><a href="/cumulus/docs/next/operator-docs/about-operator-docs" target="_self">Operator Docs</a></li><li class=""><a href="/cumulus/docs/next/team" target="_self">Team</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Cookbooks</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">About Cookbooks<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/cumulus/docs/next/data-cookbooks/about-cookbooks">About Cookbooks</a></li><li class="navListItem"><a class="navItem" href="/cumulus/docs/next/data-cookbooks/setup">Data Cookbooks Setup</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Cookbooks<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/cumulus/docs/next/data-cookbooks/hello-world">HelloWorld Workflow</a></li><li class="navListItem"><a class="navItem" href="/cumulus/docs/next/data-cookbooks/sns">SNS Notification in Workflows</a></li><li class="navListItem"><a class="navItem" href="/cumulus/docs/next/data-cookbooks/sips-workflow">Science Investigator-led Processing Systems (SIPS)</a></li><li class="navListItem"><a class="navItem" href="/cumulus/docs/next/data-cookbooks/cnm-workflow">CNM Workflow</a></li><li class="navListItem"><a class="navItem" href="/cumulus/docs/next/data-cookbooks/error-handling">Error Handling in Workflows</a></li><li class="navListItem"><a class="navItem" href="/cumulus/docs/next/data-cookbooks/choice-states">Choice States</a></li><li class="navListItem"><a class="navItem" href="/cumulus/docs/next/data-cookbooks/cloudwatch-retention">Cloudwatch Retention</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/cumulus/docs/next/data-cookbooks/browse-generation">Ingest Browse Generation</a></li><li class="navListItem"><a class="navItem" href="/cumulus/docs/next/data-cookbooks/tracking-files">Tracking Ancillary Files</a></li><li class="navListItem"><a class="navItem" href="/cumulus/docs/next/data-cookbooks/run-tasks-in-lambda-or-docker">Run Step Function Tasks in Lambda or Docker</a></li><li class="navListItem"><a class="navItem" href="/cumulus/docs/next/data-cookbooks/throttling-queued-executions">Throttling queued executions</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"></header><article><div><span><h1><a class="anchor" aria-hidden="true" id="browse-generation"></a><a href="#browse-generation" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Browse Generation</h1>
<p>This entry documents how to setup a workflow that utilizes Cumulus's built-in granule file type configuration such that on ingest the browse data is exported to CMR.</p>
<p>We will discuss how to run a processing workflow against an inbound granule that has data but no browse generated. The workflow will generate a browse file and add the appropriate output values to the Cumulus message so that the built-in post-to-cmr task will publish the data appropriately.</p>
<h2><a class="anchor" aria-hidden="true" id="sections"></a><a href="#sections" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Sections</h2>
<ul>
<li><a href="#prerequisites">Prerequisites</a></li>
<li><a href="#configure-cumulus">Configure Cumulus</a></li>
<li><a href="#configure-ingest">Configure Ingest</a></li>
<li><a href="#run-workflows">Run Workflows</a></li>
<li><a href="#build-processing-lambda">Build Processing Lambda</a></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="prerequisites"></a><a href="#prerequisites" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Prerequisites</h2>
<h3><a class="anchor" aria-hidden="true" id="cumulus"></a><a href="#cumulus" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Cumulus</h3>
<p>This entry assumes you have a deployed instance of Cumulus v1.16.0 or later, and a working dashboard following the instructions in the <a href="../deployment/deployment-readme">deployment documentation</a>. This entry also assumes you have some knowledge of how to configure Collections, Providers and Rules and basic Cumulus operation.</p>
<p>Prior to working through this entry, you should be somewhat familiar with the <a href="hello-world">Hello World</a> example the <a href="../workflows/workflows-readme">Workflows</a> section of the documentation, and <a href="../workflows/lambda">building Cumulus lambdas</a>.</p>
<p>You should also review the <a href="setup">Data Cookbooks Setup</a> portion of the documentation as it contains useful information on the inter-task message schema expectations.</p>
<p>This entry will utilize the <a href="https://github.com/nasa/cumulus-dashboard">dashboard application</a>. You will need to have a dashboard deployed as described in the <a href="../deployment/deployment-readme">Cumulus deployment documentation</a> to follow the instructions in this example.</p>
<p>If you'd prefer to <em>not</em> utilize a running dashboard to add Collections, Providers and trigger Rules, you can set the Collection/Provider and Rule via the API, however in that instance you should be very familiar with the <a href="https://nasa.github.io/cumulus-api/">Cumulus API</a> before attempting the example in this entry.</p>
<h3><a class="anchor" aria-hidden="true" id="common-metadata-repository"></a><a href="#common-metadata-repository" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Common Metadata Repository</h3>
<p>You should be familiar with the <a href="https://earthdata.nasa.gov/about/science-system-description/eosdis-components/common-metadata-repository">Common Metadata Repository</a> and already be set up as a provider with configured collections and credentials to ingest data into CMR. You should know what the collection name and version number are.</p>
<h3><a class="anchor" aria-hidden="true" id="source-data"></a><a href="#source-data" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Source Data</h3>
<p>You should have data available for Cumulus to ingest in an S3 bucket that matches with CMR if you'd like to push a record to CMR UAT.</p>
<p>For the purposes of this entry, we will be using a pre-configured MOD09GQ version 006 CMR collection. If you'd prefer to utilize the example processing code, using mocked up data files matching the file naming convention will suffice, so long as you also have a matching collection setup in CMR.</p>
<p>If you'd prefer to ingest another data type, you will need to generate a processing lambda (see <a href="#build-processing-lambda">Build Processing Lambda</a> below).</p>
<hr>
<h2><a class="anchor" aria-hidden="true" id="configure-cumulus"></a><a href="#configure-cumulus" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Configure Cumulus</h2>
<h3><a class="anchor" aria-hidden="true" id="cmr"></a><a href="#cmr" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>CMR</h3>
<p>To run this example with successful exports to CMR you'll need to make sure the CMR configuration keys for the <code>cumulus</code> terraform module are configured per that module's <a href="https://github.com/nasa/cumulus/blob/master/tf-modules/cumulus/variables.tf">variables.tf file</a>.</p>
<h3><a class="anchor" aria-hidden="true" id="workflows"></a><a href="#workflows" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Workflows</h3>
<h4><a class="anchor" aria-hidden="true" id="summary"></a><a href="#summary" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Summary</h4>
<p>For this example, you are going to be adding two workflows to your Cumulus deployment.</p>
<ul>
<li><p>DiscoverGranulesBrowseExample</p>
<p>This workflow will run the <code>DiscoverGranules</code> task, targeting the S3 bucket/folder mentioned in the prerequisites. The output of that task will be passed into QueueGranules, which will trigger the second workflow for each granule to be ingested. The example presented here will be a single granule with a .hdf data file and a .met metadata file only, however your setup may result in more granules, or different files.</p></li>
<li><p>CookbookBrowseExample</p>
<p>This workflow will be triggered for each granule in the previous workflow. It will utilize the SyncGranule task, which brings the files into a staging location in the Cumulus buckets.</p>
<p>The output from this task will be passed into the <code>ProcessingStep</code> step , which in this example will utilize the <code>FakeProcessingLambda</code> task we provide for testing/as an example in Core, however to use your own data you will need to write a lambda that generates the appropriate CMR metadata file and accepts and returns appropriate task inputs and outputs.</p>
<p>From that task we will utilize a core task <code>FilesToGranules</code> that will transform the processing output event.input list/config.InputGranules into an array of Cumulus <a href="https://github.com/nasa/cumulus/blob/master/packages/api/models/schemas.js">granules</a> objects.</p>
<p>Using the generated granules list, we will utilize the core task <code>MoveGranules</code> to move the granules to the target buckets as defined in the collection configuration. That task will transfer the files to their final storage location and update the CMR metadata files and the granules list as output.</p>
<p>That output will be used in the <code>PostToCmr</code> task combined with the previously generated CMR file to export the granule metadata to CMR.</p></li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="workflow-configuration"></a><a href="#workflow-configuration" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Workflow Configuration</h4>
<p>Add the following to a new file <code>browse_example.tf</code> in your deployment's main directory: <a href="https://github.com/nasa/cumulus/blob/master/example/cumulus-tf/browse_example.tf">from github</a>. The file should contain the two example workflow modules.</p>
<p><strong>Please Note</strong>: You should update the <code>source =</code> line to match the current Cumulus <code>workflow</code> module release artifact to the version of Cumulus you're deploying:</p>
<pre><code class="hljs css language-hcl"><span class="hljs-attr">source</span> = <span class="hljs-string">"https://github.com/nasa/cumulus/releases/download/{version}/terraform-aws-cumulus-workflow.zip"</span>
</code></pre>
<p>A few things to note about tasks in the workflow being added:</p>
<ul>
<li>The CMR step in CookbookBrowseExample:</li>
</ul>
<pre><code class="hljs css language-json">  "CmrStep": {
    "Parameters": {
      "cma": {
        "event.$": "$",
        "task_config": {
          "bucket": "{$.meta.buckets.internal.name}",
          "stack": "{$.meta.stack}",
          "cmr": "{$.meta.cmr}",
          "launchpad": "{$.meta.launchpad}",
          "input_granules": "{$.meta.input_granules}",
          "granuleIdExtraction": "{$.meta.collection.granuleIdExtraction}"
        }
      }
    },
    "Type": "Task",
    "Resource": "${module.cumulus.post_to_cmr_task.task_arn}",
    "Retry": [
      {
        "ErrorEquals": [
          "Lambda.ServiceException",
          "Lambda.AWSLambdaException",
          "Lambda.SdkClientException"
        ],
        "IntervalSeconds": 2,
        "MaxAttempts": 6,
        "BackoffRate": 2
      }
    ],
    "Catch": [
      {
        "ErrorEquals": [
          "States.ALL"
        ],
        "ResultPath": "$.exception",
        "Next": "WorkflowFailed"
      }
    ],
    "End": true
  }
</code></pre>
<p>Note that, in the task, the <code>CmrStep.Parameters.cma.task_config.cmr</code> key will contain the values you configured in the <code>cmr</code> configuration section above.</p>
<ul>
<li>The Processing step in CookbookBrowseExample:</li>
</ul>
<pre><code class="hljs css language-json">"ProcessingStep": {
  "Parameters": {
    "cma": {
      "event.$": "$",
      "task_config": {
        "bucket": "{$.meta.buckets.internal.name}",
        "collection": "{$.meta.collection}",
        "cmrMetadataFormat": "{$.meta.cmrMetadataFormat}",
        "additionalUrls": "{$.meta.additionalUrls}",
        "generateFakeBrowse": true,
        "cumulus_message": {
          "outputs": [
            {
              "source": "{$.granules}",
              "destination": "{$.meta.input_granules}"
            },
            {
              "source": "{$.files}",
              "destination": "{$.payload}"
            }
          ]
        }
      }
    }
  },
  "Type": "Task",
  "Resource": "${module.cumulus.fake_processing_task.task_arn}",
  "Catch": [
    {
      "ErrorEquals": [
        "States.ALL"
      ],
      "ResultPath": "$.exception",
      "Next": "WorkflowFailed"
    }
  ],
  "Retry": [
    {
      "ErrorEquals": [
        "States.ALL"
      ],
      "IntervalSeconds": 2,
      "MaxAttempts": 3
    }
  ],
  "Next": "FilesToGranulesStep"
},
</code></pre>
<p>If you're not ingesting mock data matching the example, or would like to use modify the example to ingest your own data please see the <a href="#build-lambda">build-lambda</a> section below. You will need to configure a different lambda entry for your lambda and utilize it in place of the <code>Resource</code> defined in the example workflow.</p>
<p><strong>Please note</strong>: <code>FakeProcessing</code> is the core provided browse/CMR generation lambda we're using for the example in this entry.</p>
<h4><a class="anchor" aria-hidden="true" id="lambdas"></a><a href="#lambdas" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Lambdas</h4>
<p>All lambdas utilized in this example are provided in a standard deployment of Cumulus and require no additional configuration.</p>
<h4><a class="anchor" aria-hidden="true" id="redeploy"></a><a href="#redeploy" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Redeploy</h4>
<p>Once you've configured your CMR credentials, updated your workflow configuration, and updated your lambda configuration you should be able to redeploy your cumulus instance by running the following commands:</p>
<p><strong><code>terraform init</code></strong></p>
<p>You should expect to see output similar to:</p>
<pre><code class="hljs css language-sh">$ terraform init
Initializing modules...
Downloading https://github.com/nasa/cumulus/releases/download/{version}/terraform-aws-cumulus-workflow.zip <span class="hljs-keyword">for</span> cookbook_browse_example_workflow...
- cookbook_browse_example_workflow <span class="hljs-keyword">in</span> .terraform/modules/cookbook_browse_example_workflow
Downloading https://github.com/nasa/cumulus/releases/download/{version}/terraform-aws-cumulus-workflow.zip <span class="hljs-keyword">for</span> discover_granules_browse_example_workflow...
- discover_granules_browse_example_workflow <span class="hljs-keyword">in</span> .terraform/modules/discover_granules_browse_example_workflow

Initializing the backend...

Initializing provider plugins...

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running <span class="hljs-string">"terraform plan"</span> to see
any changes that are required <span class="hljs-keyword">for</span> your infrastructure. All Terraform commands
should now work.

If you ever <span class="hljs-built_in">set</span> or change modules or backend configuration <span class="hljs-keyword">for</span> Terraform,
rerun this <span class="hljs-built_in">command</span> to reinitialize your working directory. If you forget, other
commands will detect it and remind you to <span class="hljs-keyword">do</span> so <span class="hljs-keyword">if</span> necessary.
</code></pre>
<p><strong><code>terraform apply</code></strong></p>
<p>You should expect to see output similar to the following truncated example:</p>
<pre><code class="hljs css language-bash">
$ terraform apply
module.cumulus.module.archive.null_resource.rsa_keys: Refreshing state... [id=xxxxxxxxx]
data.terraform_remote_state.data_persistence: Refreshing state...
module.cumulus.module.archive.aws_cloudwatch_event_rule.daily_execution_payload_cleanup: Refreshing state... [id=xxxx]

....

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create
  ~ update <span class="hljs-keyword">in</span>-place
-/+ destroy and <span class="hljs-keyword">then</span> create replacement
 &lt;= <span class="hljs-built_in">read</span> (data resources)

Terraform will perform the following actions:
{...}
Plan: 15 to add, 3 to change, 1 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only <span class="hljs-string">'yes'</span> will be accepted to approve.

  Enter a value: yes

{...}

Apply complete! Resources: 15 added, 3 changed, 1 destroyed.
Releasing state lock. This may take a few moments...

Outputs:

archive_api_redirect_uri = {URL}
archive_api_uri = {URL}
distribution_redirect_uri = {URL}
distribution_url = {URL}
s3_credentials_redirect_uri = {URL}
</code></pre>
<hr>
<h2><a class="anchor" aria-hidden="true" id="configure-ingest"></a><a href="#configure-ingest" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Configure Ingest</h2>
<p>Now that Cumulus has been updated updated with the new workflows and code, we will use the Cumulus dashboard to configure an ingest collection, provider and rule so that we can trigger the configured workflow.</p>
<h3><a class="anchor" aria-hidden="true" id="add-collection"></a><a href="#add-collection" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Add Collection</h3>
<p>Navigate to the 'Collection' tab on the interface and add a collection. Note that you need to set the &quot;provider_path&quot; to the path on your bucket (e.g. &quot;/data&quot;) that you've staged your mock/test data.</p>
<pre><code class="hljs css language-json">{
  <span class="hljs-attr">"name"</span>: <span class="hljs-string">"MOD09GQ"</span>,
  <span class="hljs-attr">"version"</span>: <span class="hljs-string">"006"</span>,
  <span class="hljs-attr">"dataType"</span>: <span class="hljs-string">"MOD09GQ"</span>,
  <span class="hljs-attr">"process"</span>: <span class="hljs-string">"modis"</span>,
  <span class="hljs-attr">"provider_path"</span>: <span class="hljs-string">"{{path_to_data}}"</span>,
  <span class="hljs-attr">"url_path"</span>: <span class="hljs-string">"{cmrMetadata.Granule.Collection.ShortName}___{cmrMetadata.Granule.Collection.VersionId}/{substring(file.name, 0, 3)}"</span>,
  <span class="hljs-attr">"duplicateHandling"</span>: <span class="hljs-string">"replace"</span>,
  <span class="hljs-attr">"granuleId"</span>: <span class="hljs-string">"^MOD09GQ\\.A[\\d]{7}\\.[\\S]{6}\\.006\\.[\\d]{13}$"</span>,
  <span class="hljs-attr">"granuleIdExtraction"</span>: <span class="hljs-string">"(MOD09GQ\\..*)(\\.hdf|\\.cmr|_ndvi\\.jpg|\\.jpg)"</span>,
  <span class="hljs-attr">"sampleFileName"</span>: <span class="hljs-string">"MOD09GQ.A2017025.h21v00.006.2017034065104.hdf"</span>,
  <span class="hljs-attr">"files"</span>: [
    {
      <span class="hljs-attr">"bucket"</span>: <span class="hljs-string">"protected"</span>,
      <span class="hljs-attr">"regex"</span>: <span class="hljs-string">"^MOD09GQ\\.A[\\d]{7}\\.[\\S]{6}\\.006\\.[\\d]{13}\\.hdf$"</span>,
      <span class="hljs-attr">"sampleFileName"</span>: <span class="hljs-string">"MOD09GQ.A2017025.h21v00.006.2017034065104.hdf"</span>,
      <span class="hljs-attr">"type"</span>: <span class="hljs-string">"data"</span>,
      <span class="hljs-attr">"url_path"</span>: <span class="hljs-string">"{cmrMetadata.Granule.Collection.ShortName}___{cmrMetadata.Granule.Collection.VersionId}/{extractYear(cmrMetadata.Granule.Temporal.RangeDateTime.BeginningDateTime)}/{substring(file.name, 0, 3)}"</span>
    },
    {
      <span class="hljs-attr">"bucket"</span>: <span class="hljs-string">"private"</span>,
      <span class="hljs-attr">"regex"</span>: <span class="hljs-string">"^MOD09GQ\\.A[\\d]{7}\\.[\\S]{6}\\.006\\.[\\d]{13}\\.hdf\\.met$"</span>,
      <span class="hljs-attr">"sampleFileName"</span>: <span class="hljs-string">"MOD09GQ.A2017025.h21v00.006.2017034065104.hdf.met"</span>,
      <span class="hljs-attr">"type"</span>: <span class="hljs-string">"metadata"</span>
    },
    {
      <span class="hljs-attr">"bucket"</span>: <span class="hljs-string">"protected-2"</span>,
      <span class="hljs-attr">"regex"</span>: <span class="hljs-string">"^MOD09GQ\\.A[\\d]{7}\\.[\\S]{6}\\.006\\.[\\d]{13}\\.cmr\\.xml$"</span>,
      <span class="hljs-attr">"sampleFileName"</span>: <span class="hljs-string">"MOD09GQ.A2017025.h21v00.006.2017034065104.cmr.xml"</span>
    },
    {
      <span class="hljs-attr">"bucket"</span>: <span class="hljs-string">"protected"</span>,
      <span class="hljs-attr">"regex"</span>: <span class="hljs-string">"^MOD09GQ\\.A[\\d]{7}\\.[\\S]{6}\\.006\\.[\\d]{13}\\.jpg$"</span>,
      <span class="hljs-attr">"sampleFileName"</span>: <span class="hljs-string">"MOD09GQ.A2017025.h21v00.006.2017034065104.jpg"</span>
    }
  ]
}
</code></pre>
<p><strong>Please note</strong>: Even though our initial discover granules ingest brings in only the .hdf and .met files we've staged, we still configure the other possible file types for this collection's granules.</p>
<h3><a class="anchor" aria-hidden="true" id="add-provider"></a><a href="#add-provider" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Add Provider</h3>
<p>Next navigate to the Provider tab and create a provider with the following values, using whatever name you wish, and the bucket the data was staged to as the host:</p>
<pre><code class="hljs css language-shell">Name:
Protocol: S3
Host: {{data_source_bucket}}
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="add-rule"></a><a href="#add-rule" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Add Rule</h3>
<p>Once you have your provider and rule added, go to the Rules tab, and add a rule with the following values (using whatever name you wish, populating the workflow and provider keys with the previously entered values:</p>
<pre><code class="hljs css language-json">{
  <span class="hljs-attr">"name"</span>: <span class="hljs-string">"TestBrowseGeneration"</span>,
  <span class="hljs-attr">"workflow"</span>: <span class="hljs-string">"DiscoverGranulesBrowseExample"</span>,
  <span class="hljs-attr">"provider"</span>: <span class="hljs-string">"{{provider_from_previous_step}}"</span>,
  <span class="hljs-attr">"collection"</span>: {
    <span class="hljs-attr">"name"</span>: <span class="hljs-string">"MOD09GQ"</span>,
    <span class="hljs-attr">"version"</span>: <span class="hljs-string">"006"</span>
  },
  <span class="hljs-attr">"meta"</span>: {},
  <span class="hljs-attr">"rule"</span>: {
    <span class="hljs-attr">"type"</span>: <span class="hljs-string">"onetime"</span>
  },
  <span class="hljs-attr">"state"</span>: <span class="hljs-string">"ENABLED"</span>,
  <span class="hljs-attr">"updatedAt"</span>: <span class="hljs-number">1553053438767</span>
}
</code></pre>
<hr>
<h2><a class="anchor" aria-hidden="true" id="run-workflows"></a><a href="#run-workflows" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Run Workflows</h2>
<p>Once you've configured the Collection and Provider and added a onetime rule, you're ready to trigger your rule, and watch the ingest workflows process.</p>
<p>Go to the Rules tab, click the rule you just created:</p>
<p><img src="../../assets/browse_processing_1.png" alt="Screenshot of the Rules overview page with a list of rules in the Cumulus dashboard"></p>
<p>Then click the gear in the upper right corner and click &quot;Rerun&quot;:</p>
<p><img src="../../assets/browse_processing_2.png" alt="Screenshot of clicking the button to rerun a workflow rule from the rule edit page in the Cumulus dashboard"></p>
<p>Tab over to executions and you should see the <code>DiscoverGranulesBrowseExample</code> workflow run, succeed, and then moments later the <code>CookbookBrowseExample</code> should run and succeed.</p>
<p><img src="../../assets/browse_processing_3.png" alt="Screenshot of page listing executions in the Cumulus dashboard"></p>
<h3><a class="anchor" aria-hidden="true" id="results"></a><a href="#results" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Results</h3>
<p>You can verify your data has ingested by clicking the successful workflow entry:</p>
<p><img src="../../assets/browse_processing_4.png" alt="Screenshot of individual entry from table listing executions in the Cumulus dashboard"></p>
<p>Select &quot;Show Output&quot; on the next page</p>
<p><img src="../../assets/browse_processing_5.png" alt="Screenshot of &quot;Show output&quot; button from individual execution page in the Cumulus dashboard"></p>
<p>and you should see in the payload from the workflow something similar to:</p>
<pre><code class="hljs css language-json">"payload": {
  "process": "modis",
  "granules": [
    {
      "files": [
        {
          "name": "MOD09GQ.A2016358.h13v04.006.2016360104606.hdf",
          "filepath": "MOD09GQ___006/2017/MOD/MOD09GQ.A2016358.h13v04.006.2016360104606.hdf",
          "type": "data",
          "bucket": "cumulus-test-sandbox-protected",
          "filename": "s3://cumulus-test-sandbox-protected/MOD09GQ___006/2017/MOD/MOD09GQ.A2016358.h13v04.006.2016360104606.hdf",
          "time": 1553027415000,
          "path": "data",
          "url_path": "{cmrMetadata.Granule.Collection.ShortName}___{cmrMetadata.Granule.Collection.VersionId}/{extractYear(cmrMetadata.Granule.Temporal.RangeDateTime.BeginningDateTime)}/{substring(file.name, 0, 3)}",
          "duplicate_found": true,
          "size": 1908635
        },
        {
          "name": "MOD09GQ.A2016358.h13v04.006.2016360104606.hdf.met",
          "filepath": "MOD09GQ___006/MOD/MOD09GQ.A2016358.h13v04.006.2016360104606.hdf.met",
          "type": "metadata",
          "bucket": "cumulus-test-sandbox-private",
          "filename": "s3://cumulus-test-sandbox-private/MOD09GQ___006/MOD/MOD09GQ.A2016358.h13v04.006.2016360104606.hdf.met",
          "time": 1553027412000,
          "path": "data",
          "url_path": "{cmrMetadata.Granule.Collection.ShortName}___{cmrMetadata.Granule.Collection.VersionId}/{substring(file.name, 0, 3)}",
          "duplicate_found": true,
          "size": 21708
        },
        {
          "name": "MOD09GQ.A2016358.h13v04.006.2016360104606.jpg",
          "filepath": "MOD09GQ___006/2017/MOD/MOD09GQ.A2016358.h13v04.006.2016360104606.jpg",
          "type": "browse",
          "bucket": "cumulus-test-sandbox-protected",
          "filename": "s3://cumulus-test-sandbox-protected/MOD09GQ___006/2017/MOD/MOD09GQ.A2016358.h13v04.006.2016360104606.jpg",
          "time": 1553027415000,
          "path": "data",
          "url_path": "{cmrMetadata.Granule.Collection.ShortName}___{cmrMetadata.Granule.Collection.VersionId}/{extractYear(cmrMetadata.Granule.Temporal.RangeDateTime.BeginningDateTime)}/{substring(file.name, 0, 3)}",
          "duplicate_found": true,
          "size": 1908635
        },
        {
          "name": "MOD09GQ.A2016358.h13v04.006.2016360104606.cmr.xml",
          "filepath": "MOD09GQ___006/MOD/MOD09GQ.A2016358.h13v04.006.2016360104606.cmr.xml",
          "type": "metadata",
          "bucket": "cumulus-test-sandbox-protected-2",
          "filename": "s3://cumulus-test-sandbox-protected-2/MOD09GQ___006/MOD/MOD09GQ.A2016358.h13v04.006.2016360104606.cmr.xml",
          "url_path": "{cmrMetadata.Granule.Collection.ShortName}___{cmrMetadata.Granule.Collection.VersionId}/{substring(file.name, 0, 3)}"
        }
      ],
      "cmrLink": "https://cmr.uat.earthdata.nasa.gov/search/granules.json?concept_id=G1222231611-CUMULUS",
      "cmrConceptId": "G1222231611-CUMULUS",
      "granuleId": "MOD09GQ.A2016358.h13v04.006.2016360104606",
      "cmrMetadataFormat": "echo10",
      "dataType": "MOD09GQ",
      "version": "006",
      "published": true
    }
  ]
}
</code></pre>
<p>You can verify the granules exist within your cumulus instance (search using the Granules interface, check the S3 buckets, etc) and validate that the above CMR entry</p>
<hr>
<h2><a class="anchor" aria-hidden="true" id="build-processing-lambda"></a><a href="#build-processing-lambda" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Build Processing Lambda</h2>
<p>This section discusses the construction of a custom processing lambda to replace the contrived example from this entry for a real dataset processing task.</p>
<p>To ingest your own data using this example, you will need to construct your own lambda to replace the source in ProcessingStep that will generate browse imagery and provide or update a CMR metadata export file.</p>
<p>You will then need to add the lambda to your Cumulus deployment as a <code>aws_lambda_function</code> Terraform resource.</p>
<p>The discussion below outlines requirements for this lambda.</p>
<h3><a class="anchor" aria-hidden="true" id="inputs"></a><a href="#inputs" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Inputs</h3>
<p>The incoming message to the task defined in the <code>ProcessingStep</code> as configured will have the following configuration values (accessible inside event.config courtesy of the message adapter):</p>
<h4><a class="anchor" aria-hidden="true" id="configuration"></a><a href="#configuration" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Configuration</h4>
<ul>
<li><p>event.config.bucket -- the name of the bucket configured in <code>terraform.tfvars</code> as your <code>internal</code> bucket.</p></li>
<li><p>event.config.collection -- The full collection object we will configure in the <a href="#configure-ingest">Configure Ingest</a> section. You can view the expected collection schema in the docs <a href="/cumulus/docs/next/data-cookbooks/setup">here</a> or in the source code <a href="https://github.com/nasa/cumulus/blob/master/packages/api/models/schemas.js">on github</a>. You need this as available input <em>and</em> output so you can update as needed.</p></li>
</ul>
<p><code>event.config.additionalUrls</code>, <code>generateFakeBrowse</code> and <code>event.config.cmrMetadataFormat</code> from the example can be ignored as they're configuration flags for the provided example script.</p>
<h4><a class="anchor" aria-hidden="true" id="payload"></a><a href="#payload" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Payload</h4>
<p>The 'payload' from the previous task is accessible via event.input. The expected payload output schema from SyncGranules can be viewed <a href="https://github.com/nasa/cumulus/blob/master/tasks/move-granules/schemas/output.json">here</a>.</p>
<p>In our example, the payload would look like the following. <strong>Note</strong>: The types are set per-file based on what we configured in our collection, and were initially added as part of the <code>DiscoverGranules</code> step in the <code>DiscoverGranulesBrowseExample</code> workflow.</p>
<pre><code class="hljs css language-json"> "payload": {
    "process": "modis",
    "granules": [
      {
        "granuleId": "MOD09GQ.A2016358.h13v04.006.2016360104606",
        "dataType": "MOD09GQ",
        "version": "006",
        "files": [
          {
            "name": "MOD09GQ.A2016358.h13v04.006.2016360104606.hdf",
            "type": "data",
            "bucket": "cumulus-test-sandbox-internal",
            "filename": "s3://cumulus-test-sandbox-internal/file-staging/jk2/MOD09GQ___006/MOD09GQ.A2016358.h13v04.006.2016360104606.hdf",
            "fileStagingDir": "file-staging/jk2/MOD09GQ___006",
            "time": 1553027415000,
            "path": "data",
            "url_path": "{cmrMetadata.Granule.Collection.ShortName}___{cmrMetadata.Granule.Collection.VersionId}/{extractYear(cmrMetadata.Granule.Temporal.RangeDateTime.BeginningDateTime)}/{substring(file.name, 0, 3)}",
            "size": 1908635
          },
          {
            "name": "MOD09GQ.A2016358.h13v04.006.2016360104606.hdf.met",
            "type": "metadata",
            "bucket": "cumulus-test-sandbox-internal",
            "filename": "s3://cumulus-test-sandbox-internal/file-staging/jk2/MOD09GQ___006/MOD09GQ.A2016358.h13v04.006.2016360104606.hdf.met",
            "fileStagingDir": "file-staging/jk2/MOD09GQ___006",
            "time": 1553027412000,
            "path": "data",
            "url_path": "{cmrMetadata.Granule.Collection.ShortName}___{cmrMetadata.Granule.Collection.VersionId}/{substring(file.name, 0, 3)}",
            "size": 21708
          }
        ]
      }
    ]
  }
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="generating-browse-imagery"></a><a href="#generating-browse-imagery" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Generating Browse Imagery</h3>
<p>The provided example script used in the example goes through all granules and adds a 'fake' .jpg browse file to the same staging location as the data staged by prior ingest tasksf.</p>
<p>The processing lambda you construct will need to do the following:</p>
<ul>
<li>Create a browse image file based on the input data, and stage it to a location accessible to both this task and the <code>FilesToGranules</code> and <code>MoveGranules</code> tasks in a S3 bucket.</li>
<li>Add the browse file to the input granule files, making sure to set the granule file's type to <code>browse</code>.</li>
<li>Update meta.input_granules with the updated granules list, as well as provide the files to be integrated by <code>FilesToGranules</code> as output from the task.</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="generatingupdating-cmr-metadata"></a><a href="#generatingupdating-cmr-metadata" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Generating/updating CMR metadata</h3>
<p>If you do not already have a CMR file in the granules list, you will need to generate one for valid export. This example's processing script generates and adds it to the <code>FilesToGranules</code> file list via the payload but it can be present in the InputGranules from the DiscoverGranules task as well if you'd prefer to pre-generate it.</p>
<p>Both downstream tasks <code>MoveGranules</code> and <code>PostToCmr</code> expect a valid CMR file to be available if you want to export to CMR.</p>
<h3><a class="anchor" aria-hidden="true" id="expected-outputs-for-processing-tasktasks"></a><a href="#expected-outputs-for-processing-tasktasks" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Expected Outputs for processing task/tasks</h3>
<p>In the above example, the critical portion of the output to <code>FilesToGranules</code> is the payload and meta.input_granules.</p>
<p>In the example provided, the processing task is setup to return an object with the keys &quot;files&quot; and &quot;granules&quot;. In the cumulus_message configuration, the outputs are mapped in the configuration to the payload, granules to meta.input_granules:</p>
<pre><code class="hljs css language-json">          "task_config": {
            "inputGranules": "{$.meta.input_granules}",
            "granuleIdExtraction": "{$.meta.collection.granuleIdExtraction}"
          }
</code></pre>
<p>Their expected values from the example above may be useful in constructing a processing task:</p>
<h4><a class="anchor" aria-hidden="true" id="payload-1"></a><a href="#payload-1" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>payload</h4>
<p>The payload includes a full list of files to be 'moved' into the cumulus archive. The <code>FilesToGranules</code> task will take this list, merge it with the information from <code>InputGranules</code>, then pass that list to the <code>MoveGranules</code> task. The <code>MoveGranules</code> task will then move the files to their targets and update the CMR metadata file if it exists with the updated granule locations.</p>
<p>In the provided example, a payload being passed to the <code>FilesToGranules</code> task should be expected to look like:</p>
<pre><code class="hljs css language-json">  "payload": [
    "s3://cumulus-test-sandbox-internal/file-staging/jk2/MOD09GQ___006/MOD09GQ.A2016358.h13v04.006.2016360104606.hdf",
    "s3://cumulus-test-sandbox-internal/file-staging/jk2/MOD09GQ___006/MOD09GQ.A2016358.h13v04.006.2016360104606.hdf.met",
    "s3://cumulus-test-sandbox-internal/file-staging/jk2/MOD09GQ___006/MOD09GQ.A2016358.h13v04.006.2016360104606.jpg",
    "s3://cumulus-test-sandbox-internal/file-staging/jk2/MOD09GQ___006/MOD09GQ.A2016358.h13v04.006.2016360104606.cmr.xml"
  ]
</code></pre>
<p>This list is the list of granules <code>FilesToGranules</code> will act upon to add/merge with the input_granules object.</p>
<p>The pathing is generated from sync-granules, but in principle the files can be staged wherever you like so long as the processing/<code>MoveGranules</code> task's roles have access and the filename matches the collection configuration.</p>
<h4><a class="anchor" aria-hidden="true" id="input_granules"></a><a href="#input_granules" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>input_granules</h4>
<p>The <code>FilesToGranules</code> task utilizes the incoming payload to chose which files to move, but pulls all other metadata from meta.input_granules. As such, the output payload in the example would look like:</p>
<pre><code class="hljs css language-json">"input_granules": [
  {
    "granuleId": "MOD09GQ.A2016358.h13v04.006.2016360104606",
    "dataType": "MOD09GQ",
    "version": "006",
    "files": [
      {
        "name": "MOD09GQ.A2016358.h13v04.006.2016360104606.hdf",
        "type": "data",
        "bucket": "cumulus-test-sandbox-internal",
        "filename": "s3://cumulus-test-sandbox-internal/file-staging/jk2/MOD09GQ___006/MOD09GQ.A2016358.h13v04.006.2016360104606.hdf",
        "fileStagingDir": "file-staging/jk2/MOD09GQ___006",
        "time": 1553027415000,
        "path": "data",
        "url_path": "{cmrMetadata.Granule.Collection.ShortName}___{cmrMetadata.Granule.Collection.VersionId}/{extractYear(cmrMetadata.Granule.Temporal.RangeDateTime.BeginningDateTime)}/{substring(file.name, 0, 3)}",
        "duplicate_found": true,
        "size": 1908635
      },
      {
        "name": "MOD09GQ.A2016358.h13v04.006.2016360104606.hdf.met",
        "type": "metadata",
        "bucket": "cumulus-test-sandbox-internal",
        "filename": "s3://cumulus-test-sandbox-internal/file-staging/jk2/MOD09GQ___006/MOD09GQ.A2016358.h13v04.006.2016360104606.hdf.met",
        "fileStagingDir": "file-staging/jk2/MOD09GQ___006",
        "time": 1553027412000,
        "path": "data",
        "url_path": "{cmrMetadata.Granule.Collection.ShortName}___{cmrMetadata.Granule.Collection.VersionId}/{substring(file.name, 0, 3)}",
        "duplicate_found": true,
        "size": 21708
      },
      {
        "name": "MOD09GQ.A2016358.h13v04.006.2016360104606.jpg",
        "type": "browse",
        "bucket": "cumulus-test-sandbox-internal",
        "filename": "s3://cumulus-test-sandbox-internal/file-staging/jk2/MOD09GQ___006/MOD09GQ.A2016358.h13v04.006.2016360104606.jpg",
        "fileStagingDir": "file-staging/jk2/MOD09GQ___006",
        "time": 1553027415000,
        "path": "data",
        "url_path": "{cmrMetadata.Granule.Collection.ShortName}___{cmrMetadata.Granule.Collection.VersionId}/{extractYear(cmrMetadata.Granule.Temporal.RangeDateTime.BeginningDateTime)}/{substring(file.name, 0, 3)}",
        "duplicate_found": true,
      }
    ]
  }
],
</code></pre>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="/cumulus/docs/next/data-cookbooks/cloudwatch-retention"><span class="arrow-prev">← </span><span>Cloudwatch Retention</span></a><a class="docs-next button" href="/cumulus/docs/next/data-cookbooks/tracking-files"><span>Tracking Ancillary Files</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#sections">Sections</a></li><li><a href="#prerequisites">Prerequisites</a><ul class="toc-headings"><li><a href="#cumulus">Cumulus</a></li><li><a href="#common-metadata-repository">Common Metadata Repository</a></li><li><a href="#source-data">Source Data</a></li></ul></li><li><a href="#configure-cumulus">Configure Cumulus</a><ul class="toc-headings"><li><a href="#cmr">CMR</a></li><li><a href="#workflows">Workflows</a></li></ul></li><li><a href="#configure-ingest">Configure Ingest</a><ul class="toc-headings"><li><a href="#add-collection">Add Collection</a></li><li><a href="#add-provider">Add Provider</a></li><li><a href="#add-rule">Add Rule</a></li></ul></li><li><a href="#run-workflows">Run Workflows</a><ul class="toc-headings"><li><a href="#results">Results</a></li></ul></li><li><a href="#build-processing-lambda">Build Processing Lambda</a><ul class="toc-headings"><li><a href="#inputs">Inputs</a></li><li><a href="#generating-browse-imagery">Generating Browse Imagery</a></li><li><a href="#generatingupdating-cmr-metadata">Generating/updating CMR metadata</a></li><li><a href="#expected-outputs-for-processing-tasktasks">Expected Outputs for processing task/tasks</a></li></ul></li></ul></nav></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: 'f7e0be879553661f9043322d119069c8',
                indexName: 'nasa_cumulus',
                inputSelector: '#search_input_react'
              });
            </script></body></html>